{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b5d19e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Create an API Client \n",
    "from anthropic import Anthropic\n",
    "client = Anthropic()\n",
    "model = \"claude-sonnet-4-0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d74c295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "def add_user_message(messages, text):\n",
    "    user_message = {\"role\": \"user\", \"content\": text}\n",
    "    messages.append(user_message)\n",
    "\n",
    "\n",
    "def add_assistant_message(messages, text):\n",
    "    assistant_message = {\"role\": \"assistant\", \"content\": text}\n",
    "    messages.append(assistant_message)\n",
    "\n",
    "\n",
    "def chat(messages, system=None, temperature=1.0, stop_sequences=[]):\n",
    "    params = {\n",
    "        \"model\": model,\n",
    "        \"max_tokens\": 1000,\n",
    "        \"messages\": messages,\n",
    "        \"temperature\": temperature,\n",
    "        \"stop_sequences\": stop_sequences,\n",
    "    }\n",
    "\n",
    "    if system:\n",
    "        params[\"system\"] = system\n",
    "\n",
    "    message = client.messages.create(**params)\n",
    "    return message.content[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c9278cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to grade a test case + output using a model\n",
    "import json\n",
    "def grade_by_model(test_case, output):\n",
    "    eval_prompt = f\"\"\"\n",
    "You are an expert AWS code reviewer. Your task is to evaluate the following AI-generated solution.\n",
    "\n",
    "Original Task:\n",
    "<task>\n",
    "{test_case[\"task\"]}\n",
    "</task>\n",
    "\n",
    "Solution to Evaluate:\n",
    "<solution>\n",
    "{output}\n",
    "</solution>\n",
    "\n",
    "Output Format\n",
    "Provide your evaluation as a structured JSON object with the following fields, in this specific order:\n",
    "- \"strengths\": An array of 1-3 key strengths\n",
    "- \"weaknesses\": An array of 1-3 key areas for improvement\n",
    "- \"reasoning\": A concise explanation of your overall assessment\n",
    "- \"score\": A number between 1-10\n",
    "\n",
    "Respond with JSON. Keep your response concise and direct.\n",
    "Example response shape:\n",
    "{{\n",
    "    \"strengths\": string[],\n",
    "    \"weaknesses\": string[],\n",
    "    \"reasoning\": string,\n",
    "    \"score\": number\n",
    "}}\n",
    "    \"\"\"\n",
    "\n",
    "    messages = []\n",
    "    add_user_message(messages, eval_prompt)\n",
    "    add_assistant_message(messages, \"```json\")\n",
    "    eval_text = chat(messages, stop_sequences=[\"```\"])\n",
    "    return json.loads(eval_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c11eafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passes a test case into Claude\n",
    "def run_prompt(test_case):\n",
    "    prompt = f\"\"\"\n",
    "Please solve the following task:\n",
    "\n",
    "{test_case[\"task\"]}\n",
    "\"\"\"\n",
    "\n",
    "    messages = []\n",
    "    add_user_message(messages, prompt)\n",
    "    output = chat(messages)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c17db913",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to execute a single test case and grade the output\n",
    "def run_test_case(test_case):\n",
    "    \"\"\"Calls run_prompt, then grades the result\"\"\"\n",
    "    output = run_prompt(test_case)\n",
    "\n",
    "    model_grade = grade_by_model(test_case, output)\n",
    "    score = model_grade[\"score\"]\n",
    "    reasoning = model_grade[\"reasoning\"]\n",
    "\n",
    "    return {\n",
    "        \"output\": output,\n",
    "        \"test_case\": test_case,\n",
    "        \"score\": score,\n",
    "        \"reasoning\": reasoning,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81a983ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mean\n",
    "\n",
    "\n",
    "def run_eval(dataset):\n",
    "    \"\"\"Loads the dataset and calls run_test_case with each case\"\"\"\n",
    "    results = []\n",
    "\n",
    "    for test_case in dataset:\n",
    "        result = run_test_case(test_case)\n",
    "        results.append(result)\n",
    "\n",
    "    average_score = mean([result[\"score\"] for result in results])\n",
    "    print(f\"Average score: {average_score}\")\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d664d09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average score: 7\n"
     ]
    }
   ],
   "source": [
    "with open(\"test_data.json\", \"r\") as f:\n",
    "    dataset = json.load(f)\n",
    "\n",
    "results = run_eval(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0302be74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'output': 'Here\\'s a Python function to extract the AWS region from an ARN:\\n\\n```python\\ndef extract_region_from_arn(arn):\\n    \"\"\"\\n    Extract the AWS region from an Amazon Resource Name (ARN).\\n    \\n    Args:\\n        arn (str): The Amazon Resource Name\\n        \\n    Returns:\\n        str: The AWS region code, or None if not found or invalid ARN\\n        \\n    Raises:\\n        ValueError: If the ARN format is invalid\\n    \"\"\"\\n    if not arn or not isinstance(arn, str):\\n        raise ValueError(\"ARN must be a non-empty string\")\\n    \\n    # Split the ARN by colons\\n    arn_parts = arn.split(\\':\\')\\n    \\n    # ARN format: arn:partition:service:region:account-id:resource\\n    # Minimum 6 parts required\\n    if len(arn_parts) < 6:\\n        raise ValueError(\"Invalid ARN format. ARN must have at least 6 parts separated by colons\")\\n    \\n    # Check if it starts with \\'arn\\'\\n    if arn_parts[0] != \\'arn\\':\\n        raise ValueError(\"Invalid ARN format. ARN must start with \\'arn:\\'\")\\n    \\n    # Region is the 4th part (index 3)\\n    region = arn_parts[3]\\n    \\n    # Return None for empty region (global services)\\n    return region if region else None\\n\\n\\ndef extract_region_from_arn_safe(arn):\\n    \"\"\"\\n    Safe version that returns None instead of raising exceptions.\\n    \\n    Args:\\n        arn (str): The Amazon Resource Name\\n        \\n    Returns:\\n        str: The AWS region code, or None if not found or invalid ARN\\n    \"\"\"\\n    try:\\n        return extract_region_from_arn(arn)\\n    except (ValueError, AttributeError, IndexError):\\n        return None\\n\\n\\n# Example usage and test cases\\nif __name__ == \"__main__\":\\n    # Test cases\\n    test_arns = [\\n        \"arn:aws:s3:::my-bucket\",  # S3 bucket (global service, no region)\\n        \"arn:aws:s3:::my-bucket/object\",  # S3 object (global service, no region)\\n        \"arn:aws:ec2:us-west-2:123456789012:instance/i-1234567890abcdef0\",  # EC2 instance\\n        \"arn:aws:rds:eu-west-1:123456789012:db:mydb\",  # RDS database\\n        \"arn:aws:lambda:ap-southeast-1:123456789012:function:my-function\",  # Lambda function\\n        \"arn:aws:iam::123456789012:user/username\",  # IAM user (global service)\\n        \"arn:aws:dynamodb:us-east-1:123456789012:table/MyTable\",  # DynamoDB table\\n        \"invalid-arn\",  # Invalid ARN\\n        \"\",  # Empty string\\n    ]\\n    \\n    print(\"Testing extract_region_from_arn:\")\\n    for arn in test_arns:\\n        try:\\n            region = extract_region_from_arn(arn)\\n            print(f\"ARN: {arn}\")\\n            print(f\"Region: {region if region else \\'Global service (no region)\\'}\")\\n            print(\"-\" * 50)\\n        except ValueError as e:\\n            print(f\"ARN: {arn}\")\\n            print(f\"Error: {e}\")\\n            print(\"-\" * 50)\\n    \\n    print(\"\\\\nTesting safe version:\")\\n    for arn in test_arns:\\n        region = extract_region_from_arn_safe(arn)\\n        print(f\"ARN: {arn}\")\\n        print(f\"Region: {region if region else \\'Global service or invalid ARN\\'}\")\\n        print(\"-\" * 50)\\n```\\n\\nThis solution provides two functions:\\n\\n1. **`extract_region_from_arn(arn)`**: The main function that:\\n   - Validates the ARN format\\n   - Splits the ARN by colons\\n   ',\n",
       "  'test_case': {'task': 'Create a Python function to extract the AWS region from an ARN (Amazon Resource Name)'},\n",
       "  'score': 7,\n",
       "  'reasoning': 'The solution demonstrates solid understanding of ARN structure and provides robust parsing with good error handling. The core functionality is correct and the code is well-structured with helpful test cases. However, there are some misconceptions about AWS service regionality in the documentation and comments, and the region validation could be more sophisticated.'},\n",
       " {'output': 'Here\\'s a comprehensive JSON schema to validate an AWS Lambda function configuration:\\n\\n```json\\n{\\n  \"$schema\": \"http://json-schema.org/draft-07/schema#\",\\n  \"$id\": \"https://example.com/aws-lambda-config.schema.json\",\\n  \"title\": \"AWS Lambda Function Configuration\",\\n  \"description\": \"Schema for validating AWS Lambda function configuration\",\\n  \"type\": \"object\",\\n  \"required\": [\\n    \"FunctionName\",\\n    \"Runtime\",\\n    \"Role\",\\n    \"Handler\",\\n    \"Code\"\\n  ],\\n  \"properties\": {\\n    \"FunctionName\": {\\n      \"type\": \"string\",\\n      \"pattern\": \"^[a-zA-Z0-9-_]+$\",\\n      \"minLength\": 1,\\n      \"maxLength\": 64,\\n      \"description\": \"The name of the Lambda function\"\\n    },\\n    \"Runtime\": {\\n      \"type\": \"string\",\\n      \"enum\": [\\n        \"nodejs18.x\",\\n        \"nodejs16.x\",\\n        \"nodejs14.x\",\\n        \"python3.11\",\\n        \"python3.10\",\\n        \"python3.9\",\\n        \"python3.8\",\\n        \"java17\",\\n        \"java11\",\\n        \"java8\",\\n        \"dotnet6\",\\n        \"dotnetcore3.1\",\\n        \"go1.x\",\\n        \"ruby3.2\",\\n        \"ruby2.7\",\\n        \"provided.al2\",\\n        \"provided\"\\n      ],\\n      \"description\": \"The runtime environment for the Lambda function\"\\n    },\\n    \"Role\": {\\n      \"type\": \"string\",\\n      \"pattern\": \"^arn:aws:iam::[0-9]{12}:role/[a-zA-Z0-9+=,.@_-]+$\",\\n      \"description\": \"The Amazon Resource Name (ARN) of the function\\'s execution role\"\\n    },\\n    \"Handler\": {\\n      \"type\": \"string\",\\n      \"minLength\": 1,\\n      \"maxLength\": 128,\\n      \"description\": \"The name of the method within your code that Lambda calls to execute your function\"\\n    },\\n    \"Code\": {\\n      \"type\": \"object\",\\n      \"description\": \"The code for the function\",\\n      \"oneOf\": [\\n        {\\n          \"properties\": {\\n            \"ZipFile\": {\\n              \"type\": \"string\",\\n              \"description\": \"The base64-encoded contents of the deployment package\"\\n            }\\n          },\\n          \"required\": [\"ZipFile\"],\\n          \"additionalProperties\": false\\n        },\\n        {\\n          \"properties\": {\\n            \"S3Bucket\": {\\n              \"type\": \"string\",\\n              \"minLength\": 3,\\n              \"maxLength\": 63,\\n              \"description\": \"An Amazon S3 bucket in the same AWS Region as your function\"\\n            },\\n            \"S3Key\": {\\n              \"type\": \"string\",\\n              \"minLength\": 1,\\n              \"maxLength\": 1024,\\n              \"description\": \"The Amazon S3 key of the deployment package\"\\n            },\\n            \"S3ObjectVersion\": {\\n              \"type\": \"string\",\\n              \"description\": \"For versioned objects, the version of the deployment package object to use\"\\n            }\\n          },\\n          \"required\": [\"S3Bucket\", \"S3Key\"],\\n          \"additionalProperties\": false\\n        },\\n        {\\n          \"properties\": {\\n            \"ImageUri\": {\\n              \"type\": \"string\",\\n              \"pattern\": \"^[0-9]{12}\\\\\\\\.dkr\\\\\\\\.ecr\\\\\\\\.[a-z0-9-]+\\\\\\\\.amazonaws\\\\\\\\.com/[a-z0-9-_/]+:[a-zA-Z0-9-_.]+$\",\\n              \"description\": \"URI of a container image in the Amazon ECR registry\"\\n            }\\n          },\\n          \"required\": [\"ImageUri\"],\\n          \"additionalProperties\": false\\n        }\\n      ]\\n    },\\n    \"Description\": {\\n      \"type\": \"string\",\\n      \"maxLength\": 256,\\n      \"description\": \"A description of the function\"\\n    },\\n    \"Timeout\": {\\n      \"type\": \"integer',\n",
       "  'test_case': {'task': 'Write a JSON schema to validate an AWS Lambda function configuration'},\n",
       "  'score': 6,\n",
       "  'reasoning': \"The schema demonstrates solid understanding of AWS Lambda configuration validation with proper data types, patterns, and constraints for core fields. However, it's incomplete and missing significant configuration options that are commonly used in Lambda functions. The technical approach is sound but execution is unfinished.\"},\n",
       " {'output': 'I\\'ll help you create a regular expression to match valid AWS EC2 instance types. Let me break this down step by step.\\n\\n## AWS EC2 Instance Type Format\\n\\nAWS EC2 instance types follow this pattern:\\n- **Family** (1-2 letters): t, m, c, r, x, z, etc.\\n- **Generation** (1-2 digits): 1, 2, 3, 4, 5, 6, 7, etc.\\n- **Optional processor/feature** (1-2 letters): a, d, n, e, g, etc.\\n- **Dot separator**: .\\n- **Size**: nano, micro, small, medium, large, xlarge, 2xlarge, 4xlarge, etc.\\n\\n## Regular Expression\\n\\nHere\\'s a comprehensive regex pattern:\\n\\n```regex\\n^[a-z]+[0-9]+[a-z]*\\\\.(nano|micro|small|medium|large|[0-9]+xlarge)$\\n```\\n\\n## More Detailed Version\\n\\nFor better accuracy with current AWS patterns:\\n\\n```regex\\n^[a-z]{1,3}[0-9]{1,2}[a-z]{0,2}\\\\.(nano|micro|small|medium|large|[1-9][0-9]*xlarge)$\\n```\\n\\n## Implementation Examples\\n\\n### Python\\n```python\\nimport re\\n\\n# Regex pattern for AWS EC2 instance types\\nec2_pattern = r\\'^[a-z]{1,3}[0-9]{1,2}[a-z]{0,2}\\\\.(nano|micro|small|medium|large|[1-9][0-9]*xlarge)$\\'\\n\\ndef validate_ec2_instance_type(instance_type):\\n    return bool(re.match(ec2_pattern, instance_type))\\n\\n# Test cases\\ntest_instances = [\\n    \"t2.micro\",      # Valid\\n    \"m5.large\",      # Valid\\n    \"c5n.xlarge\",    # Valid\\n    \"r6g.2xlarge\",   # Valid\\n    \"x1e.32xlarge\",  # Valid\\n    \"invalid.type\",  # Invalid\\n    \"t2.invalid\",    # Invalid\\n    \"123.micro\"      # Invalid\\n]\\n\\nfor instance in test_instances:\\n    result = validate_ec2_instance_type(instance)\\n    print(f\"{instance}: {\\'Valid\\' if result else \\'Invalid\\'}\")\\n```\\n\\n### JavaScript\\n```javascript\\nconst ec2Pattern = /^[a-z]{1,3}[0-9]{1,2}[a-z]{0,2}\\\\.(nano|micro|small|medium|large|[1-9][0-9]*xlarge)$/;\\n\\nfunction validateEC2InstanceType(instanceType) {\\n    return ec2Pattern.test(instanceType);\\n}\\n\\n// Test examples\\nconst testInstances = [\\n    \"t2.micro\",\\n    \"m5.large\", \\n    \"c5n.xlarge\",\\n    \"r6g.2xlarge\"\\n];\\n\\ntestInstances.forEach(instance => {\\n    console.log(`${instance}: ${validateEC2InstanceType(instance) ? \\'Valid\\' : \\'Invalid\\'}`);\\n});\\n```\\n\\n## Pattern Breakdown\\n\\n- `^` - Start of string\\n- `[a-z]{1,3}` - Instance family (1-3 lowercase letters)\\n- `[0-9]{1,2}` - Generation number (1-2 digits)\\n- `[a-z]{0,2}` - Optional processor/feature indicators (0-2 lowercase letters)\\n- `\\\\.` - Literal dot separator\\n- `(nano|micro|small|medium|large|[1-9][0-9]*xlarge)` - Valid sizes\\n- `$` - End of string\\n\\n## Valid Matches\\n- ✅ t2.micro\\n- ✅ m5.large\\n- ✅ c5n.xlarge\\n- ✅ r6g.2xlarge\\n- ✅ x1e.32xlarge\\n- ✅ inf1.xlarge\\n\\n## Invalid Matches\\n- ❌ T2.micro (uppercase)\\n- ❌ t2.invalid (invalid size',\n",
       "  'test_case': {'task': 'Develop a regular expression to match valid AWS EC2 instance types (e.g., t2.micro, m5.large)'},\n",
       "  'score': 7,\n",
       "  'reasoning': \"The solution demonstrates strong understanding of regex fundamentals and AWS EC2 naming conventions, with excellent documentation and code examples. However, it's overly permissive and would match many invalid instance types that AWS doesn't actually offer, reducing its practical utility for strict validation.\"},\n",
       " {'output': 'Here\\'s a Python function to convert an AWS CloudFormation template from YAML to JSON:\\n\\n## Basic Version\\n\\n```python\\nimport json\\nimport yaml\\n\\ndef convert_cloudformation_yaml_to_json(yaml_content):\\n    \"\"\"\\n    Convert AWS CloudFormation template from YAML to JSON format.\\n    \\n    Args:\\n        yaml_content (str): YAML content as string\\n        \\n    Returns:\\n        str: JSON formatted CloudFormation template\\n        \\n    Raises:\\n        yaml.YAMLError: If YAML parsing fails\\n        json.JSONEncodeError: If JSON encoding fails\\n    \"\"\"\\n    try:\\n        # Parse YAML content\\n        cf_template = yaml.safe_load(yaml_content)\\n        \\n        # Convert to JSON with proper formatting\\n        json_content = json.dumps(cf_template, indent=2, default=str)\\n        \\n        return json_content\\n        \\n    except yaml.YAMLError as e:\\n        raise yaml.YAMLError(f\"Error parsing YAML: {e}\")\\n    except Exception as e:\\n        raise Exception(f\"Error converting to JSON: {e}\")\\n```\\n\\n## Enhanced Version with File I/O\\n\\n```python\\nimport json\\nimport yaml\\nimport os\\nfrom pathlib import Path\\n\\ndef convert_cf_yaml_to_json(input_source, output_path=None):\\n    \"\"\"\\n    Convert AWS CloudFormation template from YAML to JSON format.\\n    \\n    Args:\\n        input_source (str): Either YAML content string or path to YAML file\\n        output_path (str, optional): Path to save JSON file. If None, returns JSON string\\n        \\n    Returns:\\n        str: JSON formatted CloudFormation template (if output_path is None)\\n        bool: True if file was successfully written (if output_path is provided)\\n        \\n    Raises:\\n        FileNotFoundError: If input file doesn\\'t exist\\n        yaml.YAMLError: If YAML parsing fails\\n        PermissionError: If unable to write to output file\\n    \"\"\"\\n    \\n    # Determine if input is file path or content\\n    if os.path.isfile(input_source):\\n        # Read from file\\n        with open(input_source, \\'r\\', encoding=\\'utf-8\\') as file:\\n            yaml_content = file.read()\\n    else:\\n        # Treat as YAML content string\\n        yaml_content = input_source\\n    \\n    try:\\n        # Parse YAML content\\n        cf_template = yaml.safe_load(yaml_content)\\n        \\n        # Validate it\\'s a CloudFormation template (basic check)\\n        if not isinstance(cf_template, dict):\\n            raise ValueError(\"Invalid CloudFormation template: must be a dictionary\")\\n        \\n        # Convert to JSON with proper formatting\\n        json_content = json.dumps(cf_template, indent=2, default=str, sort_keys=True)\\n        \\n        if output_path:\\n            # Write to file\\n            output_file = Path(output_path)\\n            output_file.parent.mkdir(parents=True, exist_ok=True)\\n            \\n            with open(output_file, \\'w\\', encoding=\\'utf-8\\') as file:\\n                file.write(json_content)\\n            \\n            return True\\n        else:\\n            return json_content\\n            \\n    except yaml.YAMLError as e:\\n        raise yaml.YAMLError(f\"Error parsing YAML: {e}\")\\n    except PermissionError as e:\\n        raise PermissionError(f\"Permission denied writing to {output_path}: {e}\")\\n    except Exception as e:\\n        raise Exception(f\"Unexpected error during conversion: {e}\")\\n\\ndef validate_cloudformation_template(template_dict):\\n    \"\"\"\\n    Basic validation for CloudFormation template structure.\\n    \\n    Args:\\n        template_dict (dict): Parsed CloudFormation template\\n        \\n    Returns:\\n        bool: True if template appears valid\\n        \\n    Raises:\\n        ValueError: If template structure is invalid\\n    \"\"\"\\n    if not isinstance(template_dict, dict):\\n        raise ValueError(\"Template must be a dictionary\")\\n    \\n    # Check for required AWSTemplateFormatVersion or Resources\\n    if \\'AWSTemplateFormatVersion\\' not in template_dict',\n",
       "  'test_case': {'task': 'Create a Python function to convert an AWS CloudFormation template from YAML to JSON'},\n",
       "  'score': 7,\n",
       "  'reasoning': 'The solution demonstrates solid software engineering practices with good error handling, documentation, and flexible input/output options. However, the incomplete validation function and minimal CloudFormation-specific validation reduce its robustness for production use.'},\n",
       " {'output': 'Here\\'s a JSON object representing an AWS IAM policy that grants read-only access to a specific S3 bucket:\\n\\n```json\\n{\\n  \"Version\": \"2012-10-17\",\\n  \"Statement\": [\\n    {\\n      \"Effect\": \"Allow\",\\n      \"Action\": [\\n        \"s3:GetObject\",\\n        \"s3:GetObjectVersion\",\\n        \"s3:ListBucket\"\\n      ],\\n      \"Resource\": [\\n        \"arn:aws:s3:::my-specific-bucket\",\\n        \"arn:aws:s3:::my-specific-bucket/*\"\\n      ]\\n    }\\n  ]\\n}\\n```\\n\\n**Key components explained:**\\n\\n- **Version**: Specifies the policy language version (always use \"2012-10-17\")\\n- **Effect**: \"Allow\" grants the specified permissions\\n- **Action**: The read-only S3 actions:\\n  - `s3:GetObject` - Download/read objects\\n  - `s3:GetObjectVersion` - Read specific versions of objects\\n  - `s3:ListBucket` - List contents of the bucket\\n- **Resource**: Two ARN patterns:\\n  - `arn:aws:s3:::my-specific-bucket` - The bucket itself (needed for ListBucket)\\n  - `arn:aws:s3:::my-specific-bucket/*` - All objects within the bucket\\n\\n**To use this policy:**\\n1. Replace `my-specific-bucket` with your actual bucket name\\n2. Attach this policy to an IAM user, group, or role\\n\\nThis policy provides secure read-only access without allowing any modifications to the bucket or its contents.',\n",
       "  'test_case': {'task': 'Write a JSON object representing a basic AWS IAM policy allowing S3 read-only access to a specific bucket'},\n",
       "  'score': 8,\n",
       "  'reasoning': 'This is a well-crafted IAM policy that correctly implements S3 read-only access with proper resource ARNs for both bucket and object operations. The explanation is thorough and educational, covering all essential components. Minor improvements could include a more realistic bucket name example and mentioning additional read-only permissions.'}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
