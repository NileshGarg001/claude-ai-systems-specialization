{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "576188ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load env variables and create client\n",
    "from dotenv import load_dotenv\n",
    "from anthropic import Anthropic\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "client = Anthropic()\n",
    "low_model = \"claude-3-5-haiku-latest\"\n",
    "high_model = \"claude-sonnet-4-0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b77e65f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "def add_user_message(messages, text):\n",
    "    user_message = {\"role\": \"user\", \"content\": text}\n",
    "    messages.append(user_message)\n",
    "\n",
    "\n",
    "def add_assistant_message(messages, text):\n",
    "    assistant_message = {\"role\": \"assistant\", \"content\": text}\n",
    "    messages.append(assistant_message)\n",
    "\n",
    "\n",
    "def chat(model, messages, system=None, temperature=1.0, stop_sequences=[]):\n",
    "    params = {\n",
    "        \"model\": model,\n",
    "        \"max_tokens\": 1000,\n",
    "        \"messages\": messages,\n",
    "        \"temperature\": temperature,\n",
    "        \"stop_sequences\": stop_sequences,\n",
    "    }\n",
    "\n",
    "    if system:\n",
    "        params[\"system\"] = system\n",
    "\n",
    "    message = client.messages.create(**params)\n",
    "    return message.content[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "847f51ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate a new dataset\n",
    "import json\n",
    "\n",
    "\n",
    "def generate_dataset():\n",
    "    prompt = \"\"\"\n",
    "Generate a evaluation dataset for a prompt evaluation. The dataset will be used to evaluate prompts\n",
    "that generate Python, JSON, or Regex specifically for AWS-related tasks. Generate an array of JSON objects,\n",
    "each representing task that requires Python, JSON, or a Regex to complete.\n",
    "\n",
    "Example output:\n",
    "```json\n",
    "[\n",
    "    {\n",
    "        \"task\": \"Description of task\",\n",
    "        \"format\": \"json\" or \"python\" or \"regex\"\n",
    "    },\n",
    "    ...additional\n",
    "]\n",
    "```\n",
    "\n",
    "* Focus on tasks that can be solved by writing a single Python function, a single JSON object, or a regular expression.\n",
    "* Focus on tasks that do not require writing much code\n",
    "\n",
    "Please generate 6 objects.\n",
    "\"\"\"\n",
    "\n",
    "    messages = []\n",
    "    add_user_message(messages, prompt)\n",
    "    add_assistant_message(messages, \"```json\")\n",
    "    text = chat(low_model,messages, stop_sequences=[\"```\"])\n",
    "    return json.loads(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce666e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the dataset and write it to 'dataset.json'\n",
    "dataset = generate_dataset()\n",
    "with open(\"dataset.json\", \"w\") as f:\n",
    "    json.dump(dataset, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "683f700f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'task': 'Create a regex to validate an AWS S3 bucket name (lowercase, alphanumeric, 3-63 characters)',\n",
       "  'format': 'regex'},\n",
       " {'task': 'Generate a JSON schema for an AWS Lambda function configuration',\n",
       "  'format': 'json'},\n",
       " {'task': 'Write a Python function to extract region from an AWS ARN',\n",
       "  'format': 'python'},\n",
       " {'task': \"Create a regex to match AWS EC2 instance IDs (starts with 'i-')\",\n",
       "  'format': 'regex'},\n",
       " {'task': 'Create a JSON object representing minimal IAM policy for S3 read access',\n",
       "  'format': 'json'},\n",
       " {'task': 'Write a Python function to convert CloudWatch metric names to valid Python variable names',\n",
       "  'format': 'python'}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "84cd5a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to grade a test case + output using a model\n",
    "def grade_by_model(test_case, output):\n",
    "    eval_prompt = f\"\"\"\n",
    "You are an expert AWS code reviewer. Your task is to evaluate the following AI-generated solution.\n",
    "\n",
    "Original Task:\n",
    "<task>\n",
    "{test_case[\"task\"]}\n",
    "</task>\n",
    "\n",
    "Solution to Evaluate:\n",
    "<solution>\n",
    "{output}\n",
    "</solution>\n",
    "\n",
    "Output Format\n",
    "Provide your evaluation as a structured JSON object with the following fields, in this specific order:\n",
    "- \"strengths\": An array of 1-3 key strengths\n",
    "- \"weaknesses\": An array of 1-3 key areas for improvement\n",
    "- \"reasoning\": A concise explanation of your overall assessment\n",
    "- \"score\": A number between 1-10\n",
    "\n",
    "Respond with JSON. Keep your response concise and direct.\n",
    "Example response shape:\n",
    "{{\n",
    "    \"strengths\": string[],\n",
    "    \"weaknesses\": string[],\n",
    "    \"reasoning\": string,\n",
    "    \"score\": number\n",
    "}}\n",
    "    \"\"\"\n",
    "\n",
    "    messages = []\n",
    "    add_user_message(messages, eval_prompt)\n",
    "    add_assistant_message(messages, \"```json\")\n",
    "    eval_text = chat(high_model, messages, stop_sequences=[\"```\"])\n",
    "    return json.loads(eval_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "78345c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to validate the output structure\n",
    "import re\n",
    "import ast\n",
    "\n",
    "\n",
    "def validate_json(text):\n",
    "    try:\n",
    "        json.loads(text.strip())\n",
    "        return 10\n",
    "    except json.JSONDecodeError:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def validate_python(text):\n",
    "    try:\n",
    "        ast.parse(text.strip())\n",
    "        return 10\n",
    "    except SyntaxError:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def validate_regex(text):\n",
    "    try:\n",
    "        re.compile(text.strip())\n",
    "        return 10\n",
    "    except re.error:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def grade_syntax(response, test_case):\n",
    "    format = test_case[\"format\"]\n",
    "    if format == \"json\":\n",
    "        return validate_json(response)\n",
    "    elif format == \"python\":\n",
    "        return validate_python(response)\n",
    "    else:\n",
    "        return validate_regex(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e2eb1cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passes a test case into Claude\n",
    "def run_prompt(test_case):\n",
    "    prompt = f\"\"\"\n",
    "Please solve the following task:\n",
    "\n",
    "{test_case[\"task\"]}\n",
    "\n",
    "* Respond only with Python, JSON, or a plain Regex\n",
    "* Do not add any comments or commentary or explanation\n",
    "\"\"\"\n",
    "\n",
    "    messages = []\n",
    "    add_user_message(messages, prompt)\n",
    "    add_assistant_message(messages, \"```code\")\n",
    "    output = chat(high_model,messages, stop_sequences=[\"```\"])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "78f8e6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to execute a single test case and grade the output\n",
    "def run_test_case(test_case):\n",
    "    \"\"\"Calls run_prompt, then grades the result\"\"\"\n",
    "    output = run_prompt(test_case)\n",
    "\n",
    "    model_grade = grade_by_model(test_case, output)\n",
    "    model_score = model_grade[\"score\"]\n",
    "    reasoning = model_grade[\"reasoning\"]\n",
    "\n",
    "    syntax_score = grade_syntax(output, test_case)\n",
    "\n",
    "    score = (model_score + syntax_score) / 2\n",
    "\n",
    "    return {\n",
    "        \"output\": output,\n",
    "        \"test_case\": test_case,\n",
    "        \"score\": score,\n",
    "        \"reasoning\": reasoning,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "06df0c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mean\n",
    "\n",
    "\n",
    "def run_eval(dataset):\n",
    "    \"\"\"Loads the dataset and calls run_test_case with each case\"\"\"\n",
    "    results = []\n",
    "\n",
    "    for test_case in dataset:\n",
    "        result = run_test_case(test_case)\n",
    "        results.append(result)\n",
    "\n",
    "    average_score = mean([result[\"score\"] for result in results])\n",
    "    print(f\"Average score: {average_score}\")\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6652f600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average score: 7.333333333333333\n"
     ]
    }
   ],
   "source": [
    "with open(\"dataset.json\", \"r\") as f:\n",
    "    dataset = json.load(f)\n",
    "\n",
    "results = run_eval(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bd9500c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'output': '\\n^[a-z0-9][a-z0-9.-]{1,61}[a-z0-9]$\\n',\n",
       "  'test_case': {'task': 'Create a regex to validate an AWS S3 bucket name (lowercase, alphanumeric, 3-63 characters)',\n",
       "   'format': 'regex'},\n",
       "  'score': 8.0,\n",
       "  'reasoning': \"The regex implements standard AWS S3 bucket naming rules but contradicts the simplified task requirements. The task specifically requested 'alphanumeric' characters only, while the solution includes periods and hyphens from the full AWS specification.\"},\n",
       " {'output': '\\n{\\n  \"$schema\": \"http://json-schema.org/draft-07/schema#\",\\n  \"type\": \"object\",\\n  \"title\": \"AWS Lambda Function Configuration\",\\n  \"properties\": {\\n    \"FunctionName\": {\\n      \"type\": \"string\",\\n      \"pattern\": \"^[a-zA-Z0-9-_]{1,64}$\"\\n    },\\n    \"Runtime\": {\\n      \"type\": \"string\",\\n      \"enum\": [\\n        \"nodejs18.x\",\\n        \"nodejs16.x\",\\n        \"nodejs14.x\",\\n        \"python3.11\",\\n        \"python3.10\",\\n        \"python3.9\",\\n        \"python3.8\",\\n        \"java17\",\\n        \"java11\",\\n        \"java8\",\\n        \"dotnet6\",\\n        \"dotnetcore3.1\",\\n        \"go1.x\",\\n        \"ruby3.2\",\\n        \"ruby2.7\",\\n        \"provided.al2\",\\n        \"provided\"\\n      ]\\n    },\\n    \"Role\": {\\n      \"type\": \"string\",\\n      \"pattern\": \"^arn:aws:iam::[0-9]{12}:role/.+$\"\\n    },\\n    \"Handler\": {\\n      \"type\": \"string\"\\n    },\\n    \"Code\": {\\n      \"type\": \"object\",\\n      \"properties\": {\\n        \"ZipFile\": {\\n          \"type\": \"string\"\\n        },\\n        \"S3Bucket\": {\\n          \"type\": \"string\"\\n        },\\n        \"S3Key\": {\\n          \"type\": \"string\"\\n        },\\n        \"S3ObjectVersion\": {\\n          \"type\": \"string\"\\n        },\\n        \"ImageUri\": {\\n          \"type\": \"string\"\\n        }\\n      },\\n      \"oneOf\": [\\n        {\\n          \"required\": [\"ZipFile\"]\\n        },\\n        {\\n          \"required\": [\"S3Bucket\", \"S3Key\"]\\n        },\\n        {\\n          \"required\": [\"ImageUri\"]\\n        }\\n      ]\\n    },\\n    \"Description\": {\\n      \"type\": \"string\",\\n      \"maxLength\": 256\\n    },\\n    \"Timeout\": {\\n      \"type\": \"integer\",\\n      \"minimum\": 1,\\n      \"maximum\": 900\\n    },\\n    \"MemorySize\": {\\n      \"type\": \"integer\",\\n      \"minimum\": 128,\\n      \"maximum\": 10240\\n    },\\n    \"Publish\": {\\n      \"type\": \"boolean\"\\n    },\\n    \"VpcConfig\": {\\n      \"type\": \"object\",\\n      \"properties\": {\\n        \"SubnetIds\": {\\n          \"type\": \"array\",\\n          \"items\": {\\n            \"type\": \"string\",\\n            \"pattern\": \"^subnet-[0-9a-f]{8,17}$\"\\n          }\\n        },\\n        \"SecurityGroupIds\": {\\n          \"type\": \"array\",\\n          \"items\": {\\n            \"type\": \"string\",\\n            \"pattern\": \"^sg-[0-9a-f]{8,17}$\"\\n          }\\n        }\\n      }\\n    },\\n    \"Environment\": {\\n      \"type\": \"object\",\\n      \"properties\": {\\n        \"Variables\": {\\n          \"type\": \"object\",\\n          \"patternProperties\": {\\n            \"^[a-zA-Z]([a-zA-Z0-9_]){0,127}$\": {\\n              \"type\": \"string\"\\n            }\\n          }\\n        }\\n      }\\n    },\\n    \"DeadLetterConfig\": {\\n      \"type\": \"object\",\\n      \"properties\": {\\n        \"TargetArn\": {\\n          \"type\": \"string\",\\n          \"pattern\": \"^arn:aws:(sqs|sns):[a-z0-9-]+:[0-9]{12}:.+$\"\\n        }\\n      }\\n    },\\n    \"KMSKeyArn\": {\\n      \"type\": \"string\",\\n      \"pattern\": \"^arn:aws:kms:[a-z0-9-]+:[0-9]{12}:key/[a-f0-9-]{36}$\"',\n",
       "  'test_case': {'task': 'Generate a JSON schema for an AWS Lambda function configuration',\n",
       "   'format': 'json'},\n",
       "  'score': 3.0,\n",
       "  'reasoning': 'The schema demonstrates good understanding of Lambda configuration structure and validation patterns, but has critical issues with completeness and currency. The truncated JSON and outdated runtime list significantly impact its practical utility.'},\n",
       " {'output': \"\\ndef extract_region(arn):\\n    parts = arn.split(':')\\n    if len(parts) >= 4:\\n        return parts[3]\\n    return None\\n\",\n",
       "  'test_case': {'task': 'Write a Python function to extract region from an AWS ARN',\n",
       "   'format': 'python'},\n",
       "  'score': 8.0,\n",
       "  'reasoning': 'The function correctly extracts the region from valid ARNs using the standard format (arn:partition:service:region:account:resource), but lacks robust input validation and error handling that would be expected in production code.'},\n",
       " {'output': '\\n^i-[0-9a-f]{8}([0-9a-f]{9})?$\\n',\n",
       "  'test_case': {'task': \"Create a regex to match AWS EC2 instance IDs (starts with 'i-')\",\n",
       "   'format': 'regex'},\n",
       "  'score': 8.5,\n",
       "  'reasoning': 'The regex correctly identifies the core requirements and handles both legacy and current EC2 instance ID formats, but has a structural issue in the optional group that could lead to incorrect matching of 17-character suffixes instead of 17-character total IDs.'},\n",
       " {'output': '\\n{\\n  \"Version\": \"2012-10-17\",\\n  \"Statement\": [\\n    {\\n      \"Effect\": \"Allow\",\\n      \"Action\": [\\n        \"s3:GetObject\",\\n        \"s3:ListBucket\"\\n      ],\\n      \"Resource\": [\\n        \"arn:aws:s3:::*\",\\n        \"arn:aws:s3:::*/*\"\\n      ]\\n    }\\n  ]\\n}\\n',\n",
       "  'test_case': {'task': 'Create a JSON object representing minimal IAM policy for S3 read access',\n",
       "   'format': 'json'},\n",
       "  'score': 8.0,\n",
       "  'reasoning': 'While the policy structure is correct and includes the core S3 read actions, the use of wildcard resources makes it a security concern. A truly minimal policy should specify exact bucket/object resources rather than granting access to all S3 resources globally.'},\n",
       " {'output': \"\\ndef cloudwatch_metric_to_variable(metric_name):\\n    import re\\n    # Replace invalid characters with underscores\\n    variable_name = re.sub(r'[^a-zA-Z0-9_]', '_', metric_name)\\n    # Ensure it doesn't start with a digit\\n    if variable_name[0].isdigit():\\n        variable_name = '_' + variable_name\\n    # Remove consecutive underscores\\n    variable_name = re.sub(r'_+', '_', variable_name)\\n    # Remove trailing underscores\\n    variable_name = variable_name.strip('_')\\n    # Ensure it's not empty\\n    if not variable_name:\\n        variable_name = 'metric'\\n    return variable_name.lower()\\n\",\n",
       "  'test_case': {'task': 'Write a Python function to convert CloudWatch metric names to valid Python variable names',\n",
       "   'format': 'python'},\n",
       "  'score': 8.5,\n",
       "  'reasoning': 'The solution correctly addresses the core requirement of converting CloudWatch metric names to valid Python variables. It properly handles Python naming constraints and edge cases. However, the implementation has performance inefficiencies and the lowercase conversion may lose important semantic information from CloudWatch metrics.'}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
