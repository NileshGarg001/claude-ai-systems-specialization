{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "59b08dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load env variables and create client\n",
    "from dotenv import load_dotenv\n",
    "from anthropic import Anthropic\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "client = Anthropic()\n",
    "low_model = \"claude-3-5-haiku-latest\"\n",
    "high_model = \"claude-sonnet-4-0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f21c186f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "def add_user_message(messages, text):\n",
    "    user_message = {\"role\": \"user\", \"content\": text}\n",
    "    messages.append(user_message)\n",
    "\n",
    "\n",
    "def add_assistant_message(messages, text):\n",
    "    assistant_message = {\"role\": \"assistant\", \"content\": text}\n",
    "    messages.append(assistant_message)\n",
    "\n",
    "\n",
    "def chat(model, messages, system=None, temperature=1.0, stop_sequences=[]):\n",
    "    params = {\n",
    "        \"model\": model,\n",
    "        \"max_tokens\": 1000,\n",
    "        \"messages\": messages,\n",
    "        \"temperature\": temperature,\n",
    "        \"stop_sequences\": stop_sequences,\n",
    "    }\n",
    "\n",
    "    if system:\n",
    "        params[\"system\"] = system\n",
    "\n",
    "    message = client.messages.create(**params)\n",
    "    return message.content[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a20e5ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate a new dataset\n",
    "import json\n",
    "\n",
    "\n",
    "def generate_dataset():\n",
    "    prompt = \"\"\"\n",
    "You are an expert AI assistant tasked with creating an evaluation dataset. Your goal is to generate a dataset for a prompt-engineering pipeline that tests a model's ability to produce code for specific AWS tasks.\n",
    "\n",
    "The output must be a single, valid JSON array containing exactly **six* JSON objects.\n",
    "\n",
    "**Example Output Structure:**\n",
    "\n",
    "Your final output should follow this structure precisely. Notice how each object contains a `task`, its required `format`, and the `judging_criteria`.\n",
    "\n",
    "```json\n",
    "[\n",
    "  {\n",
    "    \"task\": \"A human-like description of a simple AWS task...\",\n",
    "    \"format\": \"python\",\n",
    "    \"judging_criteria\": \"Clear, specific rules for how to grade the Python code...\"\n",
    "  },\n",
    "  {\n",
    "    \"task\": \"Another description, this time for a JSON-based AWS task...\",\n",
    "    \"format\": \"json\",\n",
    "    \"judging_criteria\": \"Unambiguous criteria for validating the JSON structure and content...\"\n",
    "  },\n",
    "  {\n",
    "      \"task\": \"A request for a regular expression to parse some AWS log data...\",\n",
    "      \"format\": \"regex\",\n",
    "      \"judging_criteria\": \"Specific requirements for what the regex must capture...\"\n",
    "  }\n",
    "]\n",
    "```\n",
    "\n",
    "Now, generate a new and unique array of three objects based on the following detailed instructions for each key:\n",
    "\n",
    "1.  **`task`**: A string describing a common AWS-related problem. Write this as if you were a developer asking a colleague for helpâ€”it should sound natural and can be slightly informal or contain some situational context.\n",
    "2.  **`format`**: A string specifying the required output format. This value is deterministic. The three objects you create **must** have the formats `\"python\"`, `\"json\"`, and `\"regex\"`, one for each.\n",
    "3.  **`judging_criteria`**: A string containing precise, objective rules for an evaluator to check if the generated code is correct. This should be a clear checklist of what to look for in the solution.\n",
    "\n",
    "**Constraints to Follow:**\n",
    "\n",
    "  * **Domain:** All tasks must relate to common AWS services (e.g., S3, IAM, CloudWatch, Lambda).\n",
    "  * **Simplicity:** Tasks must be solvable with a single Python function, a single JSON object, or one regular expression.\n",
    "  * **Final Output:** Your response should only contain the raw JSON array and nothing else.\n",
    "\n",
    "Generate the array of six objects now.\n",
    "\"\"\"\n",
    "\n",
    "    messages = []\n",
    "    add_user_message(messages, prompt)\n",
    "    add_assistant_message(messages, \"```json\")\n",
    "    text = chat(low_model, messages, stop_sequences=[\"```\"])\n",
    "    return json.loads(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "41bba7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the dataset and write it to 'dataset.json'\n",
    "dataset = generate_dataset()\n",
    "with open(\"final_dataset.json\", \"w\") as f:\n",
    "    json.dump(dataset, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bce348c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to grade a test case + output using a model\n",
    "def grade_by_model(test_case, output):\n",
    "    eval_prompt = eval_prompt = f\"\"\"\n",
    "You are an expert AWS code reviewer. Your task is to evaluate the following AI-generated solution based on a specific set of criteria.\n",
    "\n",
    "Original Task:\n",
    "<task>\n",
    "{test_case[\"task\"]}\n",
    "</task>\n",
    "\n",
    "Judging Criteria:\n",
    "<criteria>\n",
    "{test_case[\"judging_criteria\"]}\n",
    "</criteria>\n",
    "\n",
    "Solution to Evaluate:\n",
    "<solution>\n",
    "{output}\n",
    "</solution>\n",
    "\n",
    "Your Instructions:\n",
    "Carefully compare the provided <solution> against the <criteria>. Your entire evaluation must be based on whether the solution meets the requirements outlined in the criteria.\n",
    "\n",
    "Output Format:\n",
    "Provide your evaluation as a structured JSON object with the following fields, in this specific order:\n",
    "- \"strengths\": An array of 1-3 key strengths, specifically referencing the judging criteria.\n",
    "- \"weaknesses\": An array of 1-3 key weaknesses or deviations from the judging criteria.\n",
    "- \"reasoning\": A concise explanation of your overall assessment, summarizing how well the solution adhered to the criteria.\n",
    "- \"score\": A number between 1-10, where 10 means the solution perfectly meets all judging criteria.\n",
    "\n",
    "Respond with only the raw JSON object. Keep your response concise and direct.\n",
    "Example response shape:\n",
    "{{\n",
    "    \"strengths\": [\"Adheres to the specified IAM action `s3:GetObject`.\", \"Correctly targets the resource ARN.\"],\n",
    "    \"weaknesses\": [\"Missing the `s3:ListBucket` action required by the criteria.\"],\n",
    "    \"reasoning\": \"The solution is mostly correct but incomplete, as it fails to meet one of the key requirements from the judging criteria.\",\n",
    "    \"score\": 7\n",
    "}}\n",
    "\"\"\"\n",
    "\n",
    "    messages = []\n",
    "    add_user_message(messages, eval_prompt)\n",
    "    add_assistant_message(messages, \"```json\")\n",
    "    eval_text = chat(high_model, messages, stop_sequences=[\"```\"])\n",
    "    return json.loads(eval_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1a9db809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passes a test case into Claude\n",
    "def run_prompt(task):\n",
    "    \"\"\"\n",
    "    Generates a precise, role-based prompt to guide the AI in solving a coding task.\n",
    "    The model must infer the required output format (Python, JSON, or Regex) from the task itself.\n",
    "\n",
    "    Args:\n",
    "        task: A string describing the task to be solved.\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"\n",
    "You are an expert code generation engine. Your sole purpose is to generate a single, clean code snippet to solve the user's task.\n",
    "Analyze the task below and respond with only the required code.\n",
    "\n",
    "**Task:**\n",
    "{task}\n",
    "\n",
    "**Your Instructions:**\n",
    "1.  Read the task and determine if the solution requires Python, JSON, or a regular expression.\n",
    "2.  Generate only the raw code or text that solves the task.\n",
    "3.  Your entire response must be only the solution itself. Do not add any comments, explanations, or surrounding markdown like ```.\n",
    "\"\"\"\n",
    "\n",
    "    messages = []\n",
    "    add_user_message(messages, prompt)\n",
    "    \n",
    "    # Start the model with a generic code block opener.\n",
    "    # The model is expected to fill in the language (e.g., python, json) itself.\n",
    "    add_assistant_message(messages, \"```code\")\n",
    "    output = chat(high_model,messages, stop_sequences=[\"```\"])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "06f54854",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to validate the output structure\n",
    "import re\n",
    "import ast\n",
    "\n",
    "\n",
    "def validate_json(text):\n",
    "    try:\n",
    "        json.loads(text.strip())\n",
    "        return 10\n",
    "    except json.JSONDecodeError:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def validate_python(text):\n",
    "    try:\n",
    "        ast.parse(text.strip())\n",
    "        return 10\n",
    "    except SyntaxError:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def validate_regex(text):\n",
    "    try:\n",
    "        re.compile(text.strip())\n",
    "        return 10\n",
    "    except re.error:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def grade_syntax(response, test_case):\n",
    "    format = test_case[\"format\"]\n",
    "    if format == \"json\":\n",
    "        return validate_json(response)\n",
    "    elif format == \"python\":\n",
    "        return validate_python(response)\n",
    "    else:\n",
    "        return validate_regex(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b08c445a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to execute a single test case and grade the output\n",
    "def run_test_case(test_case):\n",
    "    \"\"\"Calls run_prompt, then grades the result\"\"\"\n",
    "    output = run_prompt(test_case)\n",
    "\n",
    "    model_grade = grade_by_model(test_case, output)\n",
    "    model_score = model_grade[\"score\"]\n",
    "    reasoning = model_grade[\"reasoning\"]\n",
    "\n",
    "    syntax_score = grade_syntax(output, test_case)\n",
    "\n",
    "    score = (model_score + syntax_score) / 2\n",
    "\n",
    "    return {\n",
    "        \"output\": output,\n",
    "        \"test_case\": test_case,\n",
    "        \"score\": score,\n",
    "        \"reasoning\": reasoning,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6a89b820",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mean\n",
    "\n",
    "\n",
    "def run_eval(dataset):\n",
    "    \"\"\"Loads the dataset and calls run_test_case with each case\"\"\"\n",
    "    results = []\n",
    "\n",
    "    for test_case in dataset:\n",
    "        result = run_test_case(test_case)\n",
    "        results.append(result)\n",
    "\n",
    "    average_score = mean([result[\"score\"] for result in results])\n",
    "    print(f\"Average score: {average_score}\")\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bd708d42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average score: 8.666666666666666\n"
     ]
    }
   ],
   "source": [
    "with open(\"final_dataset.json\", \"r\") as f:\n",
    "    dataset = json.load(f)\n",
    "\n",
    "results = run_eval(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6e755f7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'output': '\\nimport time\\nimport random\\nimport string\\n\\ndef generate_unique_s3_bucket_name(prefix=\"bucket\"):\\n    # Ensure prefix is lowercase and valid\\n    prefix = prefix.lower().strip(\\'-\\')\\n    if not prefix:\\n        prefix = \"bucket\"\\n    \\n    # Generate timestamp\\n    timestamp = str(int(time.time()))\\n    \\n    # Generate random suffix for extra uniqueness\\n    random_suffix = \\'\\'.join(random.choices(string.ascii_lowercase + string.digits, k=6))\\n    \\n    # Combine parts with hyphens\\n    bucket_name = f\"{prefix}-{timestamp}-{random_suffix}\"\\n    \\n    # Ensure it meets length requirements (3-63 characters)\\n    if len(bucket_name) > 63:\\n        # Truncate prefix if necessary\\n        max_prefix_length = 63 - len(timestamp) - len(random_suffix) - 2\\n        prefix = prefix[:max_prefix_length]\\n        bucket_name = f\"{prefix}-{timestamp}-{random_suffix}\"\\n    \\n    return bucket_name\\n',\n",
       "  'test_case': {'task': 'I need a way to generate a unique S3 bucket name that follows AWS naming conventions and includes a timestamp to prevent collisions. Can you help me create a Python function for this?',\n",
       "   'format': 'python',\n",
       "   'judging_criteria': '1. Function must generate a valid S3 bucket name. 2. Name must be lowercase. 3. Include a timestamp or unique identifier. 4. Ensure name is between 3-63 characters. 5. Only use lowercase letters, numbers, and hyphens. 6. Cannot start or end with a hyphen.'},\n",
       "  'score': 9.0,\n",
       "  'reasoning': 'The solution meets most criteria well by generating lowercase names with valid characters, including timestamps for uniqueness, and handling length constraints. However, it has edge cases where it might violate the hyphen positioning rule and minimum length requirement.'},\n",
       " {'output': '\\n{\\n  \"Version\": \"2012-10-17\",\\n  \"Statement\": [\\n    {\\n      \"Sid\": \"AllowReadOnlyWithMFA\",\\n      \"Effect\": \"Allow\",\\n      \"Action\": [\\n        \"s3:GetObject\",\\n        \"s3:GetObjectVersion\",\\n        \"s3:GetObjectAcl\",\\n        \"s3:GetObjectVersionAcl\",\\n        \"s3:ListBucket\",\\n        \"s3:ListBucketVersions\",\\n        \"s3:ListBucketMultipartUploads\",\\n        \"s3:GetBucketLocation\",\\n        \"s3:GetBucketVersioning\"\\n      ],\\n      \"Resource\": [\\n        \"arn:aws:s3:::your-specific-bucket-name\",\\n        \"arn:aws:s3:::your-specific-bucket-name/*\"\\n      ],\\n      \"Condition\": {\\n        \"Bool\": {\\n          \"aws:MultiFactorAuthPresent\": \"true\"\\n        }\\n      }\\n    },\\n    {\\n      \"Sid\": \"ExplicitDenyWriteOperations\",\\n      \"Effect\": \"Deny\",\\n      \"Action\": [\\n        \"s3:PutObject\",\\n        \"s3:PutObjectAcl\",\\n        \"s3:DeleteObject\",\\n        \"s3:DeleteObjectVersion\",\\n        \"s3:DeleteBucket\",\\n        \"s3:CreateBucket\",\\n        \"s3:PutBucketAcl\",\\n        \"s3:PutBucketPolicy\",\\n        \"s3:DeleteBucketPolicy\"\\n      ],\\n      \"Resource\": [\\n        \"arn:aws:s3:::your-specific-bucket-name\",\\n        \"arn:aws:s3:::your-specific-bucket-name/*\"\\n      ]\\n    }\\n  ]\\n}\\n',\n",
       "  'test_case': {'task': 'Create a configuration for an IAM policy that restricts access to a specific S3 bucket for a read-only user with multi-factor authentication requirement.',\n",
       "   'format': 'json',\n",
       "   'judging_criteria': '1. Must be a valid IAM policy JSON structure. 2. Include Resource specification for exact S3 bucket. 3. Limit actions to read-only operations (s3:Get*, s3:List*). 4. Require MFA for policy. 5. Include explicit Deny for write/delete operations. 6. Use correct IAM policy syntax and formatting.'},\n",
       "  'score': 9.0,\n",
       "  'reasoning': 'The solution meets most criteria effectively with proper IAM structure, MFA requirements, resource targeting, and explicit denies. However, it deviates from the specific requirement to use wildcard patterns for read-only actions and includes some borderline actions.'},\n",
       " {'output': '\\n^(/aws/[^/]+/[^/]+)/(.+)$\\n',\n",
       "  'test_case': {'task': \"I need a regex to extract the AWS CloudWatch log group and log stream name from a complex log event path. The path format is like '/aws/lambda/service-name/log-stream-identifier'.\",\n",
       "   'format': 'regex',\n",
       "   'judging_criteria': \"1. Capture log group as first capture group. 2. Capture log stream as second capture group. 3. Handle variable path depths. 4. Work with paths starting with '/aws/'. 5. Correctly handle alphanumeric and hyphen characters. 6. Be as precise as possible without being overly restrictive.\"},\n",
       "  'score': 8.0,\n",
       "  'reasoning': 'The solution meets several key criteria including proper capture group ordering and character handling, but critically fails the variable path depths requirement by hardcoding exactly 3 segments for the log group. This makes it inflexible for different AWS service patterns.'},\n",
       " {'output': '\\nimport boto3\\nimport logging\\nfrom botocore.exceptions import ClientError\\nfrom typing import Dict, Optional\\n\\ndef rotate_aws_access_keys(username: str, region_name: str = \\'us-east-1\\') -> Optional[Dict[str, str]]:\\n    \"\"\"Safely rotate AWS access keys for an IAM user.\"\"\"\\n    \\n    # Configure logging\\n    logging.basicConfig(level=logging.INFO)\\n    logger = logging.getLogger(__name__)\\n    \\n    try:\\n        # Initialize IAM client\\n        iam_client = boto3.client(\\'iam\\', region_name=region_name)\\n        \\n        logger.info(f\"Starting key rotation for user: {username}\")\\n        \\n        # Get current access keys\\n        response = iam_client.list_access_keys(UserName=username)\\n        current_keys = response[\\'AccessKeyMetadata\\']\\n        \\n        logger.info(f\"Found {len(current_keys)} existing keys for user: {username}\")\\n        \\n        # Check if user already has 2 keys (AWS limit)\\n        if len(current_keys) >= 2:\\n            # Delete the oldest inactive key first\\n            inactive_keys = [key for key in current_keys if key[\\'Status\\'] == \\'Inactive\\']\\n            if inactive_keys:\\n                oldest_inactive = min(inactive_keys, key=lambda x: x[\\'CreateDate\\'])\\n                iam_client.delete_access_key(\\n                    UserName=username,\\n                    AccessKeyId=oldest_inactive[\\'AccessKeyId\\']\\n                )\\n                logger.info(f\"Deleted inactive key: {oldest_inactive[\\'AccessKeyId\\']}\")\\n            else:\\n                # If no inactive keys, delete the oldest active key\\n                oldest_key = min(current_keys, key=lambda x: x[\\'CreateDate\\'])\\n                iam_client.delete_access_key(\\n                    UserName=username,\\n                    AccessKeyId=oldest_key[\\'AccessKeyId\\']\\n                )\\n                logger.info(f\"Deleted oldest active key: {oldest_key[\\'AccessKeyId\\']}\")\\n        \\n        # Create new access key\\n        new_key_response = iam_client.create_access_key(UserName=username)\\n        new_access_key = new_key_response[\\'AccessKey\\']\\n        \\n        logger.info(f\"Created new access key: {new_access_key[\\'AccessKeyId\\']}\")\\n        \\n        # Deactivate old active keys (don\\'t delete immediately for safety)\\n        current_keys_updated = iam_client.list_access_keys(UserName=username)[\\'AccessKeyMetadata\\']\\n        for key in current_keys_updated:\\n            if key[\\'AccessKeyId\\'] != new_access_key[\\'AccessKeyId\\'] and key[\\'Status\\'] == \\'Active\\':\\n                iam_client.update_access_key(\\n                    UserName=username,\\n                    AccessKeyId=key[\\'AccessKeyId\\'],\\n                    Status=\\'Inactive\\'\\n                )\\n                logger.info(f\"Deactivated old key: {key[\\'AccessKeyId\\']}\")\\n        \\n        logger.info(f\"Key rotation completed successfully for user: {username}\")\\n        \\n        # Return new key details (handle securely)\\n        return {\\n            \\'AccessKeyId\\': new_access_key[\\'AccessKeyId\\'],\\n            \\'SecretAccessKey\\': new_access_key[\\'SecretAccessKey\\'],\\n            \\'Status\\': \\'Active\\',\\n            \\'CreateDate\\': new_access_key[\\'CreateDate\\'].isoformat()\\n        }\\n        \\n    except ClientError as e:\\n        error_code = e.response[\\'Error\\'][\\'Code\\']\\n        error_message = e.response[\\'Error\\'][\\'Message\\']\\n        \\n        if error_code == \\'NoSuchEntity\\':\\n            logger.error(f\"User {username} does not exist\")\\n        elif error_code == \\'LimitExceeded\\':\\n            logger.error(f\"Access key limit exceeded for user {username}\")\\n        elif error_code == \\'AccessDenied\\':\\n            logger.error(f\"Access denied for user {username}\")\\n        else:\\n            logger.error(f\"AWS IAM error: {error_code} - {error_message}\")\\n            \\n        return None\\n        \\n    except',\n",
       "  'test_case': {'task': 'Write a Python function to safely rotate AWS access keys for an IAM user, handling potential errors and logging the process.',\n",
       "   'format': 'python',\n",
       "   'judging_criteria': '1. Use boto3 library for AWS interactions. 2. Create new access key before deleting old one. 3. Handle potential IAM API errors gracefully. 4. Log key rotation events. 5. Ensure no more than two active keys per user. 6. Return new key details securely.'},\n",
       "  'score': 2.0,\n",
       "  'reasoning': 'While the solution demonstrates good understanding of boto3, logging, and error handling, it fails on the most critical safety requirement by deleting keys before creating new ones, which could leave users without access. The incomplete code and insecure return of credentials are additional significant issues.'},\n",
       " {'output': '\\n{\\n  \"AWSTemplateFormatVersion\": \"2010-09-09\",\\n  \"Resources\": {\\n    \"LambdaErrorRateAlarm\": {\\n      \"Type\": \"AWS::CloudWatch::Alarm\",\\n      \"Properties\": {\\n        \"AlarmName\": \"Lambda-Error-Rate-Alarm\",\\n        \"AlarmDescription\": \"Alarm for Lambda function error rate monitoring\",\\n        \"MetricName\": \"Errors\",\\n        \"Namespace\": \"AWS/Lambda\",\\n        \"Statistic\": \"Sum\",\\n        \"Period\": 300,\\n        \"EvaluationPeriods\": 2,\\n        \"DatapointsToAlarm\": 2,\\n        \"Threshold\": 5,\\n        \"ComparisonOperator\": \"GreaterThanThreshold\",\\n        \"Dimensions\": [\\n          {\\n            \"Name\": \"FunctionName\",\\n            \"Value\": \"your-lambda-function-name\"\\n          }\\n        ],\\n        \"AlarmActions\": [\\n          {\\n            \"Ref\": \"SNSTopicArn\"\\n          }\\n        ],\\n        \"TreatMissingData\": \"notBreaching\",\\n        \"Unit\": \"Count\"\\n      }\\n    },\\n    \"SNSTopic\": {\\n      \"Type\": \"AWS::SNS::Topic\",\\n      \"Properties\": {\\n        \"TopicName\": \"lambda-error-notifications\",\\n        \"DisplayName\": \"Lambda Error Notifications\"\\n      }\\n    },\\n    \"SNSTopicArn\": {\\n      \"Type\": \"AWS::SNS::Topic\",\\n      \"Properties\": {\\n        \"TopicName\": \"lambda-error-notifications\"\\n      }\\n    }\\n  }\\n}\\n',\n",
       "  'test_case': {'task': 'Develop a JSON configuration for a CloudWatch alarm that monitors Lambda function error rates and triggers a notification.',\n",
       "   'format': 'json',\n",
       "   'judging_criteria': '1. Include valid CloudWatch alarm JSON structure. 2. Specify metric for Lambda function errors. 3. Set appropriate threshold for error percentage. 4. Configure SNS topic for notification. 5. Include evaluation periods and datapoints to alarm. 6. Use correct AWS CloudWatch alarm syntax.'},\n",
       "  'score': 8.0,\n",
       "  'reasoning': 'The solution demonstrates good understanding of CloudWatch alarm structure and includes most required elements, but fails to properly monitor error rates as percentages and has significant issues with SNS topic configuration and referencing.'},\n",
       " {'output': '\\n^(?:\\\\d+\\\\s+)?(?:\\\\w+\\\\s+)?(?:\\\\w+-\\\\w+\\\\s+)?(\\\\d{1,3}\\\\.\\\\d{1,3}\\\\.\\\\d{1,3}\\\\.\\\\d{1,3})\\\\s+(\\\\d{1,3}\\\\.\\\\d{1,3}\\\\.\\\\d{1,3}\\\\.\\\\d{1,3})\\\\s+(\\\\d+)\\\\s+(\\\\d+)\\\\s+(\\\\d+)\\n',\n",
       "  'test_case': {'task': 'Create a regex to parse AWS VPC flow log entries, extracting source and destination IP addresses, ports, and protocol.',\n",
       "   'format': 'regex',\n",
       "   'judging_criteria': '1. Capture source IP as first group. 2. Capture destination IP as second group. 3. Extract source port as third group. 4. Extract destination port as fourth group. 5. Capture protocol as fifth group. 6. Handle different log format variations. 7. Be precise in matching IP and port formats.'},\n",
       "  'score': 8.0,\n",
       "  'reasoning': 'The solution meets most capture group requirements but has significant issues with protocol format (should be protocol name, not number) and lacks precise IP address validation. The format variation handling is attempted but not tailored to actual VPC flow log structures.'}]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2aae81f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"final_results.json\", \"w\") as f:\n",
    "    json.dump(results, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
