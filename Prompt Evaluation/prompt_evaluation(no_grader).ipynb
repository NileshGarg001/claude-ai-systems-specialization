{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1566a860",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Create an API Client \n",
    "from anthropic import Anthropic\n",
    "client = Anthropic()\n",
    "model = \"claude-sonnet-4-0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4301adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "def add_user_message(messages, text):\n",
    "    user_message = {\"role\": \"user\", \"content\": text}\n",
    "    messages.append(user_message)\n",
    "\n",
    "\n",
    "def add_assistant_message(messages, text):\n",
    "    assistant_message = {\"role\": \"assistant\", \"content\": text}\n",
    "    messages.append(assistant_message)\n",
    "\n",
    "\n",
    "def chat(messages, system=None, temperature=1.0, stop_sequences=[]):\n",
    "    params = {\n",
    "        \"model\": model,\n",
    "        \"max_tokens\": 1000,\n",
    "        \"messages\": messages,\n",
    "        \"temperature\": temperature,\n",
    "        \"stop_sequences\": stop_sequences,\n",
    "    }\n",
    "\n",
    "    if system:\n",
    "        params[\"system\"] = system\n",
    "\n",
    "    message = client.messages.create(**params)\n",
    "    return message.content[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8558069",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_prompt(test_case):\n",
    "    \"\"\"Merges the prompt and test case input, then returns the result\"\"\"\n",
    "    prompt = f\"\"\"\n",
    "Please solve the following task:\n",
    "\n",
    "{test_case[\"task\"]}\n",
    "\"\"\"\n",
    "    \n",
    "    messages = []\n",
    "    add_user_message(messages, prompt)\n",
    "    output = chat(messages)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c25c4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_test_case(test_case):\n",
    "    \"\"\"Calls run_prompt, then grades the result\"\"\"\n",
    "    output = run_prompt(test_case)\n",
    "    \n",
    "    # TODO - Grading\n",
    "    score = 10\n",
    "    \n",
    "    return {\n",
    "        \"output\": output,\n",
    "        \"test_case\": test_case,\n",
    "        \"score\": score\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b9472c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_eval(dataset):\n",
    "    \"\"\"Loads the dataset and calls run_test_case with each case\"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for test_case in dataset:\n",
    "        result = run_test_case(test_case)\n",
    "        results.append(result)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d78f792",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"test_data.json\", \"r\") as f:\n",
    "    dataset = json.load(f)\n",
    "\n",
    "results = run_eval(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "93df0f0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'output': 'Here\\'s a Python function to extract the AWS region from an ARN:\\n\\n```python\\ndef extract_region_from_arn(arn):\\n    \"\"\"\\n    Extract the AWS region from an Amazon Resource Name (ARN).\\n    \\n    Args:\\n        arn (str): The Amazon Resource Name\\n        \\n    Returns:\\n        str: The AWS region, or None if not found or invalid ARN\\n        \\n    Examples:\\n        >>> extract_region_from_arn(\"arn:aws:s3:us-west-2:123456789012:bucket/my-bucket\")\\n        \\'us-west-2\\'\\n        >>> extract_region_from_arn(\"arn:aws:iam::123456789012:user/username\")\\n        \\'\\'\\n        >>> extract_region_from_arn(\"invalid-arn\")\\n        None\\n    \"\"\"\\n    if not isinstance(arn, str):\\n        return None\\n    \\n    # ARN format: arn:partition:service:region:account-id:resource\\n    arn_parts = arn.split(\\':\\')\\n    \\n    # ARN must have at least 6 parts\\n    if len(arn_parts) < 6:\\n        return None\\n    \\n    # Check if it starts with \\'arn\\'\\n    if arn_parts[0] != \\'arn\\':\\n        return None\\n    \\n    # Region is the 4th part (index 3)\\n    region = arn_parts[3]\\n    \\n    return region\\n\\ndef extract_region_from_arn_with_validation(arn):\\n    \"\"\"\\n    Extract the AWS region from an ARN with additional validation.\\n    \\n    Args:\\n        arn (str): The Amazon Resource Name\\n        \\n    Returns:\\n        str: The AWS region, or None if not found or invalid ARN\\n        \\n    Raises:\\n        ValueError: If the ARN format is invalid\\n    \"\"\"\\n    if not isinstance(arn, str):\\n        raise ValueError(\"ARN must be a string\")\\n    \\n    # ARN format: arn:partition:service:region:account-id:resource\\n    arn_parts = arn.split(\\':\\')\\n    \\n    # ARN must have at least 6 parts\\n    if len(arn_parts) < 6:\\n        raise ValueError(\"Invalid ARN format: ARN must have at least 6 parts separated by colons\")\\n    \\n    # Check if it starts with \\'arn\\'\\n    if arn_parts[0] != \\'arn\\':\\n        raise ValueError(\"Invalid ARN format: ARN must start with \\'arn\\'\")\\n    \\n    # Validate partition (usually \\'aws\\', \\'aws-cn\\', \\'aws-us-gov\\')\\n    valid_partitions = [\\'aws\\', \\'aws-cn\\', \\'aws-us-gov\\']\\n    if arn_parts[1] not in valid_partitions:\\n        raise ValueError(f\"Invalid partition: {arn_parts[1]}. Must be one of {valid_partitions}\")\\n    \\n    # Region is the 4th part (index 3)\\n    region = arn_parts[3]\\n    \\n    return region\\n\\n# Additional utility function to check if region is valid\\ndef is_valid_aws_region(region):\\n    \"\"\"\\n    Check if a region string is a valid AWS region format.\\n    \\n    Args:\\n        region (str): The region string to validate\\n        \\n    Returns:\\n        bool: True if the region format is valid, False otherwise\\n    \"\"\"\\n    if not region:\\n        return True  # Empty region is valid for some services like IAM\\n    \\n    # Basic regex pattern for AWS regions\\n    import re\\n    pattern = r\\'^[a-z]{2}-[a-z]+-\\\\d+$\\'\\n    return bool(re.match(pattern, region))\\n\\n# Example usage and test cases\\nif __name__ == \"__main__\":\\n    # Test cases\\n    test_arns = [\\n        \"arn:aws:s3:us-west-2:123456789012:bucket/my-bucket\",\\n        \"arn:aws:ec2:eu-west-1:123456789012:instance/i-1234567890abcdef0\",\\n        \"arn:aws:iam',\n",
       "  'test_case': {'task': 'Create a Python function to extract the AWS region from an ARN (Amazon Resource Name)'},\n",
       "  'score': 10},\n",
       " {'output': 'Here\\'s a comprehensive JSON schema to validate an AWS Lambda function configuration:\\n\\n```json\\n{\\n  \"$schema\": \"http://json-schema.org/draft-07/schema#\",\\n  \"$id\": \"https://example.com/aws-lambda-config.schema.json\",\\n  \"title\": \"AWS Lambda Function Configuration\",\\n  \"description\": \"Schema for validating AWS Lambda function configuration\",\\n  \"type\": \"object\",\\n  \"required\": [\\n    \"FunctionName\",\\n    \"Runtime\",\\n    \"Role\",\\n    \"Handler\",\\n    \"Code\"\\n  ],\\n  \"properties\": {\\n    \"FunctionName\": {\\n      \"type\": \"string\",\\n      \"pattern\": \"^[a-zA-Z0-9-_]{1,64}$\",\\n      \"description\": \"The name of the Lambda function\"\\n    },\\n    \"Runtime\": {\\n      \"type\": \"string\",\\n      \"enum\": [\\n        \"nodejs18.x\",\\n        \"nodejs16.x\",\\n        \"nodejs14.x\",\\n        \"python3.11\",\\n        \"python3.10\",\\n        \"python3.9\",\\n        \"python3.8\",\\n        \"java17\",\\n        \"java11\",\\n        \"java8.al2\",\\n        \"dotnet6\",\\n        \"go1.x\",\\n        \"ruby3.2\",\\n        \"ruby2.7\",\\n        \"provided.al2\",\\n        \"provided\"\\n      ],\\n      \"description\": \"The runtime environment for the Lambda function\"\\n    },\\n    \"Role\": {\\n      \"type\": \"string\",\\n      \"pattern\": \"^arn:aws:iam::[0-9]{12}:role/.+$\",\\n      \"description\": \"The Amazon Resource Name (ARN) of the function\\'s execution role\"\\n    },\\n    \"Handler\": {\\n      \"type\": \"string\",\\n      \"pattern\": \"^[^\\\\\\\\s]+$\",\\n      \"description\": \"The name of the method within your code that Lambda calls to execute your function\"\\n    },\\n    \"Code\": {\\n      \"type\": \"object\",\\n      \"description\": \"The code for the function\",\\n      \"oneOf\": [\\n        {\\n          \"properties\": {\\n            \"ZipFile\": {\\n              \"type\": \"string\",\\n              \"description\": \"The base64-encoded contents of the deployment package\"\\n            }\\n          },\\n          \"required\": [\"ZipFile\"],\\n          \"additionalProperties\": false\\n        },\\n        {\\n          \"properties\": {\\n            \"S3Bucket\": {\\n              \"type\": \"string\",\\n              \"pattern\": \"^[a-z0-9.-]{3,63}$\",\\n              \"description\": \"An Amazon S3 bucket in the same AWS Region as your function\"\\n            },\\n            \"S3Key\": {\\n              \"type\": \"string\",\\n              \"minLength\": 1,\\n              \"maxLength\": 1024,\\n              \"description\": \"The Amazon S3 key of the deployment package\"\\n            },\\n            \"S3ObjectVersion\": {\\n              \"type\": \"string\",\\n              \"description\": \"For versioned objects, the version of the deployment package object to use\"\\n            }\\n          },\\n          \"required\": [\"S3Bucket\", \"S3Key\"],\\n          \"additionalProperties\": false\\n        },\\n        {\\n          \"properties\": {\\n            \"ImageUri\": {\\n              \"type\": \"string\",\\n              \"pattern\": \"^[0-9]{12}\\\\\\\\.dkr\\\\\\\\.ecr\\\\\\\\.[a-z0-9-]+\\\\\\\\.amazonaws\\\\\\\\.com/.+$\",\\n              \"description\": \"URI of a container image in the Amazon ECR registry\"\\n            }\\n          },\\n          \"required\": [\"ImageUri\"],\\n          \"additionalProperties\": false\\n        }\\n      ]\\n    },\\n    \"Description\": {\\n      \"type\": \"string\",\\n      \"maxLength\": 256,\\n      \"description\": \"A description of the function\"\\n    },\\n    \"Timeout\": {\\n      \"type\": \"integer\",\\n      \"minimum\": 1,\\n      \"maximum\": 900,\\n      \"default\": 3,\\n      \"description\": \"The amount of time (in seconds) that Lambda allows a function to run before stopping it\"\\n    },\\n    \"',\n",
       "  'test_case': {'task': 'Write a JSON schema to validate an AWS Lambda function configuration'},\n",
       "  'score': 10},\n",
       " {'output': 'I\\'ll help you create a regular expression to match valid AWS EC2 instance types. Let me break this down based on the AWS EC2 instance naming convention.\\n\\n## AWS EC2 Instance Type Format\\n\\nAWS EC2 instance types follow this pattern: `[family][generation].[size]`\\n\\n- **Family**: 1-3 letters (e.g., t, m, c, r, x, z, u, i, d, h, f, g, p, inf, trn)\\n- **Generation**: 1-2 digits\\n- **Size**: Various sizes like nano, micro, small, medium, large, xlarge, 2xlarge, etc.\\n\\n## Regular Expression\\n\\nHere\\'s a comprehensive regex pattern:\\n\\n```regex\\n^[a-z]{1,3}[0-9]{1,2}\\\\.(nano|micro|small|medium|large|xlarge|[0-9]+xlarge)$\\n```\\n\\n## More Specific Version\\n\\nFor a more precise match based on actual AWS instance families:\\n\\n```regex\\n^(a1|c[3-7]|d[2-3]|f1|g[3-5]|h1|i[2-4]|inf[1-2]|m[3-7]|p[2-5]|r[3-7]|t[2-4]|u-[0-9]+tb1|x[1-2]|z1d)\\\\.(nano|micro|small|medium|large|xlarge|[0-9]+xlarge)$\\n```\\n\\n## Implementation Examples\\n\\n### Python\\n```python\\nimport re\\n\\ndef validate_ec2_instance_type(instance_type):\\n    pattern = r\\'^[a-z]{1,3}[0-9]{1,2}\\\\.(nano|micro|small|medium|large|xlarge|[0-9]+xlarge)$\\'\\n    return bool(re.match(pattern, instance_type))\\n\\n# Test cases\\ntest_instances = [\\n    \"t2.micro\",      # Valid\\n    \"m5.large\",      # Valid\\n    \"c5.4xlarge\",    # Valid\\n    \"r6i.24xlarge\",  # Valid\\n    \"invalid\",       # Invalid\\n    \"t2.invalid\"     # Invalid\\n]\\n\\nfor instance in test_instances:\\n    print(f\"{instance}: {validate_ec2_instance_type(instance)}\")\\n```\\n\\n### JavaScript\\n```javascript\\nfunction validateEC2InstanceType(instanceType) {\\n    const pattern = /^[a-z]{1,3}[0-9]{1,2}\\\\.(nano|micro|small|medium|large|xlarge|[0-9]+xlarge)$/;\\n    return pattern.test(instanceType);\\n}\\n\\n// Test cases\\nconst testInstances = [\"t2.micro\", \"m5.large\", \"c5.4xlarge\", \"invalid\"];\\ntestInstances.forEach(instance => {\\n    console.log(`${instance}: ${validateEC2InstanceType(instance)}`);\\n});\\n```\\n\\n## Pattern Breakdown\\n\\n- `^` - Start of string\\n- `[a-z]{1,3}` - 1-3 lowercase letters for instance family\\n- `[0-9]{1,2}` - 1-2 digits for generation\\n- `\\\\.` - Literal dot separator\\n- `(nano|micro|small|medium|large|xlarge|[0-9]+xlarge)` - Valid size options\\n- `$` - End of string\\n\\n## Valid Examples\\n- `t2.micro`\\n- `m5.large`\\n- `c5.4xlarge`\\n- `r6i.24xlarge`\\n- `inf1.xlarge`\\n\\n## Invalid Examples\\n- `invalid-type`\\n- `t2.invalid`\\n- `5m.large`\\n- `t2.`\\n\\nThis regex pattern will accurately match the standard AWS EC2 instance type naming convention while being flexible enough to accommodate new instance families and generations that AWS may introduce.',\n",
       "  'test_case': {'task': 'Develop a regular expression to match valid AWS EC2 instance types (e.g., t2.micro, m5.large)'},\n",
       "  'score': 10},\n",
       " {'output': 'Here\\'s a Python function to convert an AWS CloudFormation template from YAML to JSON:\\n\\n## Basic Version\\n\\n```python\\nimport yaml\\nimport json\\n\\ndef convert_yaml_to_json(yaml_file_path, json_file_path=None):\\n    \"\"\"\\n    Convert AWS CloudFormation template from YAML to JSON format.\\n    \\n    Args:\\n        yaml_file_path (str): Path to the input YAML file\\n        json_file_path (str, optional): Path to save the JSON file. \\n                                      If None, returns JSON string.\\n    \\n    Returns:\\n        str: JSON string if json_file_path is None\\n        None: If json_file_path is provided (saves to file)\\n    \"\"\"\\n    try:\\n        # Read YAML file\\n        with open(yaml_file_path, \\'r\\', encoding=\\'utf-8\\') as yaml_file:\\n            yaml_data = yaml.safe_load(yaml_file)\\n        \\n        # Convert to JSON\\n        json_data = json.dumps(yaml_data, indent=2, ensure_ascii=False)\\n        \\n        # Save to file or return string\\n        if json_file_path:\\n            with open(json_file_path, \\'w\\', encoding=\\'utf-8\\') as json_file:\\n                json_file.write(json_data)\\n            print(f\"Successfully converted {yaml_file_path} to {json_file_path}\")\\n        else:\\n            return json_data\\n            \\n    except FileNotFoundError:\\n        print(f\"Error: File {yaml_file_path} not found\")\\n    except yaml.YAMLError as e:\\n        print(f\"Error parsing YAML: {e}\")\\n    except json.JSONEncodeError as e:\\n        print(f\"Error converting to JSON: {e}\")\\n    except Exception as e:\\n        print(f\"Unexpected error: {e}\")\\n```\\n\\n## Enhanced Version with Additional Features\\n\\n```python\\nimport yaml\\nimport json\\nimport os\\nfrom pathlib import Path\\n\\ndef convert_cloudformation_yaml_to_json(\\n    yaml_file_path, \\n    json_file_path=None, \\n    validate_cf=True,\\n    pretty_print=True\\n):\\n    \"\"\"\\n    Convert AWS CloudFormation template from YAML to JSON format with validation.\\n    \\n    Args:\\n        yaml_file_path (str): Path to the input YAML file\\n        json_file_path (str, optional): Path to save the JSON file\\n        validate_cf (bool): Whether to perform basic CloudFormation validation\\n        pretty_print (bool): Whether to format JSON with indentation\\n    \\n    Returns:\\n        dict: Dictionary containing \\'success\\' status and \\'data\\' or \\'error\\'\\n    \"\"\"\\n    try:\\n        # Validate input file exists\\n        if not os.path.exists(yaml_file_path):\\n            return {\"success\": False, \"error\": f\"File {yaml_file_path} not found\"}\\n        \\n        # Read YAML file\\n        with open(yaml_file_path, \\'r\\', encoding=\\'utf-8\\') as yaml_file:\\n            yaml_data = yaml.safe_load(yaml_file)\\n        \\n        # Basic CloudFormation validation\\n        if validate_cf:\\n            validation_result = _validate_cloudformation_template(yaml_data)\\n            if not validation_result[\"valid\"]:\\n                return {\\n                    \"success\": False, \\n                    \"error\": f\"CloudFormation validation failed: {validation_result[\\'error\\']}\"\\n                }\\n        \\n        # Convert to JSON with proper formatting\\n        indent = 2 if pretty_print else None\\n        json_data = json.dumps(yaml_data, indent=indent, ensure_ascii=False, sort_keys=True)\\n        \\n        # Save to file or return data\\n        if json_file_path:\\n            # Create directory if it doesn\\'t exist\\n            Path(json_file_path).parent.mkdir(parents=True, exist_ok=True)\\n            \\n            with open(json_file_path, \\'w\\', encoding=\\'utf-8\\') as json_file:\\n                json_file.write(json_data)\\n            \\n            return {\\n                \"success\": True,\\n                \"message\": f\"Successfully',\n",
       "  'test_case': {'task': 'Create a Python function to convert an AWS CloudFormation template from YAML to JSON'},\n",
       "  'score': 10},\n",
       " {'output': 'Here\\'s a JSON object representing a basic AWS IAM policy that allows read-only access to a specific S3 bucket:\\n\\n```json\\n{\\n  \"Version\": \"2012-10-17\",\\n  \"Statement\": [\\n    {\\n      \"Sid\": \"S3ReadOnlyAccess\",\\n      \"Effect\": \"Allow\",\\n      \"Action\": [\\n        \"s3:GetObject\",\\n        \"s3:GetObjectVersion\",\\n        \"s3:ListBucket\"\\n      ],\\n      \"Resource\": [\\n        \"arn:aws:s3:::your-bucket-name\",\\n        \"arn:aws:s3:::your-bucket-name/*\"\\n      ]\\n    }\\n  ]\\n}\\n```\\n\\n**Key components explained:**\\n\\n- **Version**: Uses the current policy language version\\n- **Statement**: Contains the permission rules\\n- **Sid**: Statement ID (optional, but helpful for identification)\\n- **Effect**: \"Allow\" grants the specified permissions\\n- **Action**: \\n  - `s3:GetObject` - Read/download objects\\n  - `s3:GetObjectVersion` - Access object versions\\n  - `s3:ListBucket` - List objects in the bucket\\n- **Resource**: \\n  - `arn:aws:s3:::your-bucket-name` - The bucket itself (needed for listing)\\n  - `arn:aws:s3:::your-bucket-name/*` - All objects within the bucket\\n\\n**To use this policy:**\\n1. Replace `your-bucket-name` with your actual S3 bucket name\\n2. Attach this policy to an IAM user, group, or role\\n\\nThis policy provides read-only access while preventing any write, delete, or administrative operations on the bucket.',\n",
       "  'test_case': {'task': 'Write a JSON object representing a basic AWS IAM policy allowing S3 read-only access to a specific bucket'},\n",
       "  'score': 10}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
